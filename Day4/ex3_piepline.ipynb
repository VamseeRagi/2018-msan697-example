{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import *\n",
    "sc = SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load the data and create an RDD (16 pixels and label)\n",
    "pen_raw = sc.textFile(\"../Data/penbased.dat\", 4).map(lambda x:  x.split(\", \")).map(lambda row: [float(x) for x in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "penschema = StructType([\n",
    "    StructField(\"pix1\",DoubleType(),True),\n",
    "    StructField(\"pix2\",DoubleType(),True),\n",
    "    StructField(\"pix3\",DoubleType(),True),\n",
    "    StructField(\"pix4\",DoubleType(),True),\n",
    "    StructField(\"pix5\",DoubleType(),True),\n",
    "    StructField(\"pix6\",DoubleType(),True),\n",
    "    StructField(\"pix7\",DoubleType(),True),\n",
    "    StructField(\"pix8\",DoubleType(),True),\n",
    "    StructField(\"pix9\",DoubleType(),True),\n",
    "    StructField(\"pix10\",DoubleType(),True),\n",
    "    StructField(\"pix11\",DoubleType(),True),\n",
    "    StructField(\"pix12\",DoubleType(),True),\n",
    "    StructField(\"pix13\",DoubleType(),True),\n",
    "    StructField(\"pix14\",DoubleType(),True),\n",
    "    StructField(\"pix15\",DoubleType(),True),\n",
    "    StructField(\"pix16\",DoubleType(),True),\n",
    "    StructField(\"label\",DoubleType(),True)\n",
    "])\n",
    "\n",
    "dfpen = sqlContext.createDataFrame(pen_raw.map(lambda x : Row(x[0],x[1],x[2],x[3],x[4],x[5],x[6],x[7],x[8],x[9],x[10],x[11],x[12],x[13],x[14],x[15],x[16])), penschema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Training and Test data.\n",
    "pendtsets = dfpen.randomSplit([0.8, 0.2])\n",
    "pendttrain = pendtsets[0].cache()\n",
    "pendtvalid = pendtsets[1].cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transformer - Vector Assembler.\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "va = VectorAssembler(outputCol=\"features\", inputCols=dfpen.columns[0:-1]) #except the last col."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Estimator - DecisionTreeClassifier which creates a transformer (Decision Tree Classifier model)\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(maxDepth=20, maxBins= 32, minInstancesPerNode=1, minInfoGain = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit the pipeline to training documents.\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[va,dt])\n",
    "dtmodel = pipeline.fit(pendttrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtpredicts = dtmodel.transform(pendtvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0364635\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(dtpredicts)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {Row(label=0.0, prediction=0.0): 218,\n",
       "             Row(label=0.0, prediction=1.0): 1,\n",
       "             Row(label=0.0, prediction=3.0): 1,\n",
       "             Row(label=0.0, prediction=4.0): 1,\n",
       "             Row(label=0.0, prediction=8.0): 2,\n",
       "             Row(label=0.0, prediction=9.0): 1,\n",
       "             Row(label=1.0, prediction=1.0): 198,\n",
       "             Row(label=1.0, prediction=2.0): 11,\n",
       "             Row(label=1.0, prediction=3.0): 1,\n",
       "             Row(label=1.0, prediction=4.0): 1,\n",
       "             Row(label=1.0, prediction=5.0): 1,\n",
       "             Row(label=1.0, prediction=7.0): 3,\n",
       "             Row(label=1.0, prediction=9.0): 1,\n",
       "             Row(label=2.0, prediction=1.0): 7,\n",
       "             Row(label=2.0, prediction=2.0): 182,\n",
       "             Row(label=2.0, prediction=3.0): 1,\n",
       "             Row(label=2.0, prediction=7.0): 1,\n",
       "             Row(label=3.0, prediction=2.0): 2,\n",
       "             Row(label=3.0, prediction=3.0): 207,\n",
       "             Row(label=3.0, prediction=5.0): 2,\n",
       "             Row(label=3.0, prediction=6.0): 1,\n",
       "             Row(label=3.0, prediction=7.0): 3,\n",
       "             Row(label=3.0, prediction=9.0): 2,\n",
       "             Row(label=4.0, prediction=4.0): 200,\n",
       "             Row(label=4.0, prediction=5.0): 1,\n",
       "             Row(label=4.0, prediction=6.0): 1,\n",
       "             Row(label=4.0, prediction=9.0): 3,\n",
       "             Row(label=5.0, prediction=1.0): 1,\n",
       "             Row(label=5.0, prediction=5.0): 190,\n",
       "             Row(label=5.0, prediction=7.0): 1,\n",
       "             Row(label=5.0, prediction=8.0): 2,\n",
       "             Row(label=5.0, prediction=9.0): 3,\n",
       "             Row(label=6.0, prediction=0.0): 2,\n",
       "             Row(label=6.0, prediction=6.0): 194,\n",
       "             Row(label=7.0, prediction=1.0): 2,\n",
       "             Row(label=7.0, prediction=3.0): 2,\n",
       "             Row(label=7.0, prediction=6.0): 1,\n",
       "             Row(label=7.0, prediction=7.0): 192,\n",
       "             Row(label=7.0, prediction=8.0): 1,\n",
       "             Row(label=8.0, prediction=0.0): 1,\n",
       "             Row(label=8.0, prediction=7.0): 3,\n",
       "             Row(label=8.0, prediction=8.0): 168,\n",
       "             Row(label=8.0, prediction=9.0): 2,\n",
       "             Row(label=9.0, prediction=4.0): 1,\n",
       "             Row(label=9.0, prediction=5.0): 3,\n",
       "             Row(label=9.0, prediction=9.0): 180})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtpredicts.select('label','prediction').rdd.map(lambda x : (x,1)).countByKey() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
